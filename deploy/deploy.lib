# vim: ft=sh:

# # A library for deployment via Spack
#
# This library assumes the following environmental variables:
#
# * `DEPLOYMENT_ROOT` for the installation directory
# * `DEPLOYMENT_DATA` containing tarballs of proprietary software
# * `DEPLOYMENT_DATE` to force a date for the installation directory

DEFAULT_DEPLOYMENT_DATE=${DEFAULT_DEPLOYMENT_DATE:-$(date +%Y-%m-%d)}

# A list of stages in the order they will be built
stages="compilers tools serial-libraries parallel-libraries applications"

# Definitions for the installation spec generation. For every stage
# mentioned above, this should be a list of filenames *without* extension
# found in `packages`.
declare -A spec_definitions=([compilers]=compilers
                             [tools]=tools
                             [serial-libraries]="serial-libraries python-packages"
                             [parallel-libraries]=parallel-libraries
                             [applications]=bbp-packages)

# Export installed software as packages to be re-used later
# Allowed values: yes/no
#
# Rationale:
# * compilers end up in their configuration file
# * tools + serial libraries should be exported
# * for serial, parallel libraries: use in chains (see below) to get
#   dependency DAG
declare -A export_packages=([compilers]=no
                            [tools]=yes
                            [serial-libraries]=yes
                            [parallel-libraries]=no
                            [applications]=no)

# Re-use installed software via the chain mechanism
# Allowed values: yes/no
declare -A include_in_chain=([compilers]=no
                             [tools]=no
                             [serial-libraries]=yes
                             [parallel-libraries]=yes
                             [applications]=yes)

# Set up the dependency graph
declare -A spec_parentage
last=""
for stage in $stages; do
    if [[ -n "$last" ]]; then
        spec_parentage[$stage]="$last"
    fi
    last="$stage"
done

log() {
    date="$(tput smul)$(date +%H:%M:%S)$(tput rmul)"
    echo "$(tput bold)### ${date} $@$(tput sgr0)" >&2
}

install_dir_raw() {
    # Create an installation directory name based on the environment
    # variables set.
    what=$1
    date="${DEPLOYMENT_DATE:-${DEFAULT_DEPLOYMENT_DATE}}"
    name="${DEPLOYMENT_ROOT}/install/${what}/${date}"
    echo "${name}"
}

install_dir_name() {
    # Create an installation directory name based on the environment
    # variables set. Resovles any symlinks.
    what=$1
    name=$(install_dir_raw ${what})
    if [[ -L "${name}" ]]; then
        echo "$(readlink -f ${name})"
    else
        echo "${name}"
    fi
}

set_latest() {
    # Set the "latest" symlink to the current deployment date
    what=$1
    source="$(install_dir_name ${what})"
    DEPLOYMENT_DATE="latest"
    target="$(install_dir_raw ${what})"
    if [[ -e "${target}" && ! -L "${target}" ]]; then
        log "link target is not a symlink: ${target}"
        return 1
    elif [[ "${source}" = "${target}" ]]; then
        log "cannot link to itself: ${source}"
        log "returning!"
        return 0
    elif [[ ! -d "${source}" ]]; then
        log "link source is not a directory: ${source}"
        return 1
    fi
    log "creating symlink for ${what}"
    log "...from ${source}"
    log "...to   ${target}"
    rm -f "${target}"
    ln -s "${source}" "${target}"
}

install_dir() {
    # Create an installation directory based on the environment variables
    # set.
    #
    # When DEPLOYMENT_DATE is set to "latest" and the corresponding symlink
    # does not resolve/is not existing, find the last installation
    # directory and symlink it to "latest".
    what=$1
    date="${DEPLOYMENT_DATE:-${DEFAULT_DEPLOYMENT_DATE}}"
    name="$(install_dir_name ${what})"
    if [[ ! -e "${name}" && "${date}" = "latest" ]]; then
        log "creating symlink for ${date}"
        target=$(last_install_dir ${what})
        if [[ ! -d "${target}" ]]; then
            DEPLOYMENT_DATE=${DEFAULT_DEPLOYMENT_DATE}
            target="$(install_dir_name ${what})"
            log "...creating ${target}"
            mkdir -p "${target}"
        fi
        log "...from ${target}"
        log "...to   ${name}"
        ln -sf "${target}" "${name}"
    fi

    if [[ -L "${name}" ]]; then
        echo "$(readlink -f ${name})"
    else
        echo "${name}"
    fi
}

last_install_dir() {
    # Obtain the installation directory of a parental stage, i.e.,
    # compilers when building tools. Based on some assumptions:
    #
    # 1. Attempt to use the globally set `DEPLOYMENT_DATE` or default via
    #    `install_dir`
    # 2. Otherwise, use the latest directory present
    what=$1
    name="$(install_dir_name ${what})"
    if [[ ! -d "${name}" && -d "${DEPLOYMENT_ROOT}/install/${what}" ]]; then
        name=$(find "${DEPLOYMENT_ROOT}/install/${what}" -mindepth 1 -maxdepth 1 -type d|sort|tail -n1)
    fi
    echo "$(readlink -f ${name})"
}

list_module_paths() {
    # Print all module paths up to and including the stage passed as first
    # argument
    local what="$1"
    while read -d' ' stage; do
        local base="$(last_install_dir ${stage})"
        for modpath in ${base}/modules/tcl/*; do
            if [[ -d "${modpath}" ]]; then
                echo "${modpath}"
            fi
        done

        if [[ "${stage}" = "${what}" ]]; then
            return
        fi
    done <<< "${stages}"
}

update_module_path() {
    # Export MODULEPATH including all stages up to and excluding the one
    # passed as first argument
    local what="$1"
    local modpaths=$(list_module_paths ${what})

    for modpath in ${modpaths}; do
        if [[ "${stage}" = "${what}" ]]; then
            return
        fi
        grep -oF "${modpath}" <<< ${MODULEPATH} || {
            log "appending to MODULEPATH: ${modpath}"
            MODULEPATH="${MODULEPATH}${MODULEPATH:+:}${modpath}"
            export MODULEPATH
        }
    done
}

update_chain_config() {
    what="$1"
    conf="${HOME}/.spack/config.yaml"
    ckey="^\s*upstream_spack_installations:"

    read -d' ' root <<< "${stages}"
    if [[ "${what}" = "${root}" ]]; then
        return
    fi

    chains=""
    for stage in ${stages}; do
        if [[ "${stage}" = "${what}" ]]; then
            break
        fi
        if [[ "${include_in_chain[${stage}]}" = "yes" ]]; then
            chains="${stage}${chains:+ }${chains}"
        fi
    done

    if [[ -z "${chains}" ]]; then
        log "no chains in use for '${what}'"
        return
    fi

    grep -e ${ckey} ${conf} || {
        echo "  upstream_spack_installations:" >> "${conf}"
    }
    log "chaining up ${what}"
    for stage in ${chains}; do
        log "...adding ${stage}"
        cat << EOF >> "${conf}"
  - spack-install-prefix: $(last_install_dir ${stage})
    modules:
      tcl: $(last_install_dir ${stage})/modules
EOF
    done
}

configure_compilers() {
    # Add modules for compilers themselves
    update_module_path "tools"
    while read -r line; do
        set +o nounset
        spack load ${line}
        set -o nounset
        if [[ ${line} != *"intel-parallel-studio"* ]]; then
            spack compiler find --scope=user
        fi

        if [[ ${line} = *"intel"* ]]; then
            GCC_DIR=$(spack location --install-dir gcc@6.4.0)

            # update intel modules to use gcc@6.4.0 in .cfg files
            install_dir=$(spack location --install-dir ${line})
            for f in $(find ${install_dir} -name "icc.cfg" -o -name "icpc.cfg" -o -name "ifort.cfg"); do
                if ! grep -q "${GCC_DIR}" $f; then
                    echo "-gcc-name=${GCC_DIR}/bin/gcc" >> ${f}
                    echo "-Xlinker -rpath=${GCC_DIR}/lib" >> ${f}
                    echo "-Xlinker -rpath=${GCC_DIR}/lib64" >> ${f}
                    log "updated ${f} with newer GCC"
                fi
            done
        elif [[ ${line} = *"pgi"* ]]; then
            #update pgi modules for network installation
            PGI_DIR=$(dirname $(which makelocalrc))
            makelocalrc ${PGI_DIR} -gcc ${GCC_DIR}/bin/gcc -gpp ${GCC_DIR}/bin/g++ -g77 ${GCC_DIR}/bin/gfortran -x -net

            #configure pgi network license
            template=$(find $PGI_DIR -name localrc* | tail -n 1)
            for node in bbpv1 bbpv2 bbptadm tds03 tds04 r2i3n0 r2i3n1 r2i3n2 r2i3n3 r2i3n4 r2i3n5 r2i3n6; do
                cp $template $PGI_DIR/localrc.$node || true
            done
        fi
        spack unload ${line}
    done

    sed  -i 's#.*f\(77\|c\): null#      f\1: /usr/bin/gfortran#' ${HOME}/.spack/compilers.yaml
}

setup_mirror() {
    if [[ -z "${SPACK_SOURCE_MIRROR_DIR:+x}" ]]; then
        log "need to have \$SPACK_SOURCE_MIRROR_DIR set!"
        return 1
    fi
    log "adding source mirror: ${SPACK_SOURCE_MIRROR_DIR}"
    spack mirror add --scope=user my_source_mirror file://${SPACK_SOURCE_MIRROR_DIR} || log "source mirror already added!"

    if [[ -z "${SPACK_BINARY_MIRROR_DIR:+x}" ]]; then
        log "need to have \$SPACK_BINARY_MIRROR_DIR set!"
        return 1
    elif [[ "${BUILDCACHE:-x}" != "true" ]]; then
        return
    fi
    log "adding binary mirror: ${SPACK_BINARY_MIRROR_DIR}"
    spack mirror add --scope=user my_binary_mirror file://${SPACK_BINARY_MIRROR_DIR} || log "binary mirror already added!"
}

populate_mirror() {
    what=$1

    log "populating mirror for ${what}"

    specfile="$(install_dir ${what})/data/specs.txt"
    spec_list=$(spack filter --not-installed $(cat ${specfile}))

    if [[ -z "${spec_list}" ]]; then
        log "...found no new packages"
        return 0
    fi

    if [[ "${what}" = "compilers" ]]; then
        for compiler in intel intel-parallel-studio pgi; do
            mkdir -p ${SPACK_SOURCE_MIRROR_DIR}/${compiler}
            cp ${DEPLOYMENT_DATA}/${compiler}/* ${SPACK_SOURCE_MIRROR_DIR}/${compiler}/
        done
    fi

    log "found the following specs"
    echo "${spec_list}"
    spack mirror create -D -d ${SPACK_SOURCE_MIRROR_DIR} ${spec_list}
}

check_specs() {
    spack spec -Il "$@"
}

generate_specs() {
    what="$@"

    if [[ -z "${what}" ]]; then
        log "asked to generate no specs!"
        return 1
    fi

    venv="${DEPLOYMENT_ROOT}/deploy/venv"

    log "updating the deployment virtualenv"
    # Recreate the virtualenv and update the command line
    mkdir -p ${venv}
    virtualenv -q -p $(which python) ${venv} --clear
    set +o nounset
    . ${venv}/bin/activate
    set -o nounset
    pip install -q --force-reinstall -U .

    for stage in ${what}; do
        log "generating specs for ${stage}"
        datadir="$(install_dir ${stage})/data"

        mkdir -p "${datadir}"
        env &> "${datadir}/spack_deploy.env"
        git rev-parse HEAD &> "${datadir}/spack_deploy.version"

        rm -f "${datadir}/specs.txt"
        for stub in ${spec_definitions[$stage]}; do
            log "...using ${stub}.yaml"
            spackd --input packages/${stub}.yaml packages x86_64 >> "${datadir}/specs.txt"
        done
    done
}

copy_configuration() {
    what="$1"

    log "copying configuration"
    log "...into ${HOME}"
    rm -rf "${HOME}/.spack"
    mkdir -p "${HOME}/.spack"
    cp configs/*.yaml "${HOME}/.spack"

    if [[ ${spec_parentage[${what}]+_} ]]; then
        parent="${spec_parentage[$what]}"
        pdir="$(last_install_dir ${parent})"
        log "...using configuration output of ${parent}"
        cp "${pdir}/data/packages.yaml" "${HOME}/.spack"
        cp "${pdir}/data/compilers.yaml" "${HOME}/.spack"
    fi

    if [[ -d "configs/${what}" ]]; then
        log "...using specialized configuration files: $(ls configs/${what})"
        cp configs/${what}/*.yaml "${HOME}/.spack"
    fi
}

copy_configuration_user() {
    what="$1"

    local source="$(install_dir ${what})/data"
    local target="${DEPLOYMENT_ROOT}/user"
    local modpaths=$(list_module_paths ${what})

    log "copying configuration"
    log "...from ${source}"
    log "...into ${target}"

    mkdir -p "${target}"
    cp ${source}/{compilers,.spack/config,packages}.yaml ${target}

    rm -f ${target}/modules.sh
    for modpath in ${modpaths}; do
        echo "MODULEPATH=\"\${MODULEPATH}\${MODULEPATH:+:}${modpath}\"" >> ${target}/modules.sh
    done
    echo "export MODULEPATH" >> ${target}/modules.sh
}

install_specs() {
    what="$1"

    location="$(install_dir ${what})"
    HOME="${location}/data"
    SOFTS_DIR_PATH="${location}"
    MODS_DIR_PATH="${location}/modules"
    export HOME SOFTS_DIR_PATH MODS_DIR_PATH

    copy_configuration "${what}"
    update_chain_config "${what}"
    update_module_path "${what}"

    # This directory may fail intel builds, pre-emptively remove it.
    rm -rf "${HOME}/intel/.pset"

    log "sourcing spack environment"
    . ${DEPLOYMENT_ROOT}/deploy/spack/share/spack/setup-env.sh
    env &> "${HOME}/spack.env"
    (cd "${DEPLOYMENT_ROOT}/deploy/spack" && git rev-parse HEAD) &> "${HOME}/spack.version"

    log "installed specs"
    spack find

    log "gathering specs"
    spec_list=$(spack filter --not-installed $(< ${HOME}/specs.txt))

    setup_mirror

    # INSTALLED CACHED
    if [[ "${BUILDCACHE:-x}" = "true" ]]; then
        log "installing from buildcache"
        install_commands=$(spack buildcache list ${spec_list}|sed -n '/^spack buildcache install/p')
        while read cmd; do
            $cmd
        done <<< "${install_commands}"

        log "updating gathered specs"
        spec_list=$(spack filter --not-installed $(< ${HOME}/specs.txt))
    fi

    populate_mirror "${what}"

    # SPEC CHECK
    if [[ -n "${spec_list}" ]]; then
        log "found the following uninstalled specs"
        echo "${spec_list}"
        log "checking specs"
        spack spec -Il ${spec_list}
    else
        log "no specs to install?"
    fi

    # INSTALL
    #
    # use all specs to get the right unit test setup
    log "running installation for all specs"
    spack install -y --log-format=junit --log-file="${HOME}/stack.xml" $(< "${HOME}/specs.txt")

    # BUILD CACHE
    if [[ -n "${spec_list}" && -n "${SPACK_BINARY_MIRROR_DIR:+x}" ]]; then
        log "creating build caches"
        while read spec; do
            log "...caching ${spec}"
            spack buildcache create -f "${spec}" || true
        done <<< "${spec_list}"
        log "syncing build cache to mirror"
        mkdir -p "${SPACK_BINARY_MIRROR_DIR}"
        rsync -av build_cache "${SPACK_BINARY_MIRROR_DIR}"
    fi

    # Do not activate any packages for now. Maybe with lmodâ€¦
    # if [[ "${what}" = "serial-libraries" ]]; then
    #     log "running activation for python"
    #     while read spec; do
    #         if [[ "${spec}" = py-* ]]; then
    #             spack activate $spec || true
    #         fi
    #     done < "${HOME}/specs.txt"
    # fi

    mkdir -p "${WORKSPACE:-.}/stacks"
    cp "${HOME}/stack.xml" "${WORKSPACE:-.}/stacks/${what}.xml"

    spack module tcl refresh -y --latest
    . ${DEPLOYMENT_ROOT}/deploy/spack/share/spack/setup-env.sh
    if [[ "${export_packages[${what}]}" = "yes" ]]; then
        log "augmenting packages.yaml"
        spack export --scope=user --module tcl --explicit --exclude 'py-.*' > "${HOME}/packages.yaml"
    else
        log "copying packages.yaml"
        cp "${HOME}/.spack/packages.yaml" "${HOME}"
    fi

    if [[ "${what}" = "compilers" ]]; then
        log "adding compilers"
        configure_compilers < "${HOME}/specs.txt"
    fi

    cp "${HOME}/.spack/compilers.yaml" "${HOME}" || true
}

